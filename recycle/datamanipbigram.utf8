000 training
01 33
01 39
02 14
03 05
03 22
03 24
03 62
04 51
04 63
05 65
07 80
08 98
09 26
09 87
10 validation
100 for
100 validation
1000 and
1000 our
1000 settings
1000 to
1080ti gpus
11 08
11 with
12 as
14 23
14 71
15 41
18 68
1995 for
1997 malisiewicz
1998 krizhevsky
1e for
20 50
20 70
20 75
20 accuracy
2002 we
2010 hard
2011 and
2011 recent
2012 and
2013 imdb
2013 while
2014 and
2015 park
2016 72
2016 base
2016 for
2016 it
2016 pretrained
2016 to
2017 andreas
2017 cubuk
2017 katharopoulos
2017 lemley
2017 mirza
2017 peng
2017 use
2017 xie
2018 34
2018 36
2018 38
2018 and
2018 another
2018 as
2018 back
2018 but
2018 fan
2018 giridhara
2018 has
2018 learns
2018 or
2018 regardless
2018 similarly
2018 that
2018 this
2018 to
2018 tran
2018 validating
2018 we
2019 33
2019 54
2019 additionally
2019 and
2019 deriving
2019 for
2019 introduced
2019 is
2019 the
2019 was
2019 we
2019 while
21 28
21 88
22 98
23 42
23 44
24 92
25 08
25 81
26 58
26 63
26 76
270 such
28 50
29 67
32 04
32 36
32 45
32 88
32 89
33 32
33 88
34 37
34 84
34 base
35 37
35 59
35 76
35 88
36 09
36 51
36 83
37 03
37 69
37 82
38 02
38 09
38 92
38 95
40 denotes
40 imdb
40 trec
42 15
42 47
42 90
42 91
44 63
45 59
49 83
4e for
50 100
50 random
51 54
51 90
52 58
54 64
54 69
54 76
54 91
55 35
55 90
57 42
58 55
58 58
59 62
59 81
60 85
61 54
62 32
62 65
62 68
63 01
63 55
63 65
64 66
64 78
64gb ram
65 21
65 32
65 62
65 93
66 81
67 73
67 81
68 21
68 94
69 03
69 51
70 81
71 14
71 76
72 20
72 29
72 89
73 19
73 20
74 35
74 61
75 04
75 08
75 32
76 03
76 14
76 63
76 89
78 72
79 35
79 38
80 73
81 49
81 65
81 69
81 82
82 25
82 88
83 11
83 84
84 26
84 76
86 42
86 54
86 99
87 23
88 25
88 26
88 28
88 42
88 60
89 01
89 07
89 15
90 18
90 79
90 labels
91 71
91 98
92 57
93 86
94 88
95 03
98 67
98 79
98 81
99 47
above data
above formally
above gradient
above it
above observation
above optimization
above reward
above two
above update
accuracy if
achieve 100
achieved by
achieved easily
achieved impressive
achieved in
achieves superior
across all
action and
action given
actual parameterization
adaboost freund
adam optimization
adapt an
adapted formulation
adaptive augmentation
adaptively from
adaptively generating
adapts the
adding the
additive transforms
addressing class
adjusts the
adopt any
advantage that
after training
again consistently
al 2010
al 2011
al 2012
al 2015
al domains
algorithm computation
algorithm differs
algorithm figure
algorithm from
algorithm in
algorithm is
algorithm joint
algorithm next
algorithm optimizes
algorithm that
algorithm to
algorithm where
algorithm zheng
algorithms are
algorithms largely
algorithms significantly
all experiments
all other
all reported
all results
all settings
all the
alleviated the
also achieved
also cold
also each
also establishes
also leveraged
also more
also observe
also observed
also shows
also study
also tested
also tried
alternatingly corresponding
alternative parameterizations
alternatively rφ
although visually
amount and
amount of
an action
an augmentation
an em
an entire
an example
an image
an initial
an interesting
an original
analysis benchmark
and 100
and 64gb
and adapts
and also
and and
and class
and did
and dynamically
and efficiency
and emotionally
and enable
and epoch
and eq
and explore
and fischer
and fit
and fleuret
and from
and grey
and imdb
and in
and instantiation
and intrinsic
and introduces
and its
and learning
and manually
and meta
and minimizes
and model
and obtain
and osindero
and parameter
and parameterizing
and previous
and produced
and provide
and pθ
and reinforcement
and ren
and resnet
and respectively
and reward
and roth
and sample
and select
and show
and slickly
and so
and target
and trained
and two
and updated
and used
and variational
and vary
and were
and will
and yields
andreas 2019
another type
any data
any manipulation
any off
applicable scopes
application scope
application settings
applied to
applies label
approach adapts
approach besides
approach builds
approach by
approach can
approach does
approach draws
approach greatly
approach including
approach make
approach of
approach provides
approach ren
approach significantly
approach treats
approach uses
approach with
approaches cubuk
approaches designed
approaches have
approaches in
approaches such
approaches xie
approximate the
approximation jang
are alternative
are available
are averaged
are balancing
are discrete
are equivalent
are evaluated
are excited
are imbalanced
are included
are initialized
are iteratively
are learned
are more
are parameters
are small
are superior
are then
are too
are treated
argmaxθ ex
argmaxφ dv
argmaxφ ep
around 50
around accuracy
art approach
artificial examples
artificial samples
as adaboost
as also
as case
as contextual
as function
as gans
as gφ0
as is
as it
as label
as learning
as manipulation
as our
as parameters
as pθ
as special
as usual
as we
as weighting
as with
assign an
assigns an
associated with
at addressing
at each
augment data
augment each
augmentation 37
augmentation applies
augmentation approach
augmentation approaches
augmentation behavior
augmentation can
augmentation cubuk
augmentation distribution
augmentation for
augmentation kobayashi
augmentation language
augmentation mechanism
augmentation method
augmentation operators
augmentation or
augmentation our
augmentation performs
augmentation shows
augmentation tends
augmentation that
augmentation though
augmentation weighting
augmentation which
augmented update
augmenting by
augmenting only
augmenting with
automate any
automate the
automated augmentation
automatically fine
available both
available while
average number
avoid exploding
back translation
backpropagate the
backpropagated to
balancing parameters
baluja and
base uncased
based algorithm
based data
based method
based synonym
based weighting
be achieved
be applied
be because
be beneficial
be instantiated
be learned
be more
be parameterized
be policy
be published
be sentence
be suitable
be very
become increasingly
been less
been pretrained
been used
behavior as
being data
being initialized
benchmark datasets
benchmark socher
beneficial in
beneficial the
beneficial to
bert base
bert classifier
bert language
bert which
besides compared
besides our
best across
best on
best step
better at
better use
between and
between data
between the
binary movie
bland in
blue arrows
boost base
boost the
both augmentation
both datasets
both manipulation
both methods
both of
both text
boxes in
broadly applicable
build the
builds upon
built this
burden and
by additionally
by decaying
by flipping
by generating
by inducing
by instantiating
by learning
by noting
by our
by parameterizing
by randomly
by relaxing
by rδ
can adapt
can easily
can fail
can have
can lead
can potentially
can receive
can see
can sometimes
can still
cancels the
carefully designed
case study
cases to
cases where
certain types
challenges for
chang et
changing the
choose strong
cifar10 classification
cifar10 data
cifar10 the
cifar10 used
class has
class instances
class is
class question
class since
class the
class we
classes are
classes the
classification all
classification augmenting
classification can
classification for
classification on
classification results
classification similarly
classification specifically
classification tasks
classifier model
clearer note
code and
coherent with
cold grey
colors list
column is
combination of
common data
common heuristicbased
commonly used
compare our
comparing the
comparison approaches
computation flow
concretely in
condition of
conditional bert
conditional generation
conditional model
conditioning label
configuration can
connect the
connection of
consider the
consistency of
consistently better
consistently outperforms
constant by
contexts augmentation
contrast learning
contrast notpretrained
contrast the
conventional approach
conventional synonym
corpus and
corresponding to
could have
could in
create augmented
creates entire
cropping mirroring
crucially depended
curriculum jiang
dashed arrows
data 35
data 38
data 52
data 64
data augmented
data available
data cubuk
data dependent
data distribution
data domain
data domains
data during
data example
data gets
data instances
data interestingly
data of
data our
data point
data results
data size
data such
data the
data to
data transformation
data transformer
data val
dataset names
dataset we
dataset while
datasets are
datasets besides
datasets imbalanced
datasets including
datasets pose
datasets to
datasets well
decaying the
deep neural
define sample
demonstrate in
demonstrate two
denote backward
denote forward
denotes 40
denotes the
depended on
dependent reward
derived based
derived for
derives data
deriving sample
descent on
descent to
designed manually
designed specifically
detailed in
details in
develop our
developed automated
developed new
developed novel
deviation the
devise method
did not
difference following
difference in
different applicable
different application
different classes
different contexts
different from
different perspective
different problem
different schemes
difficult settings
directions on
directions we
directly backpropagate
directly be
discrete to
discuss in
distance between
distinct data
distinct methods
distinct paradigm
distribution as
distribution exp
distribution hence
distribution kl
distribution the
divergence is
diverse data
diverse manipulation
do not
does not
domain that
domains common
draw inspiration
draws inspiration
during the
dv be
dynamically adapts
dynamically adjusts
dynamically re
each dataset
each has
each instance
each minibatch
each outperform
each step
each task
each training
each with
easily by
effectively uses
efficiency specifically
efficient gradient
either augmentation
em algorithm
emotionally desiccated
empirical data
empirically verify
enables learning
end natural
end tasks
engineering burden
enhance the
enough to
enriched objective
entire new
entropy and
entropy of
ep eq
epoch charming
epoch we
eq 12
eq as
eq respectively
eq vanilla
eq αkl
equal contribution
equals the
equation shows
equivalence to
established framework
establishes the
estimates sample
estimating sample
evaluate the
evaluate two
evaluated on
even though
even when
even with
every class
evolves and
ex gφ
exact original
exact training
example 40
example data
example from
example in
example learns
example mining
example only
example plugging
example replacing
example rφ
example to
example where
examples are
examples different
examples labels
examples on
examples or
examples providing
examples we
examples with
examples without
excel in
excited to
existing rule
exp rφ
expand the
expectation of
expected extrinsic
expected reward
experimental setup
experiments are
experiments of
experiments that
experiments to
experiments were
exploding value
explore more
explore the
expressive formulation
extremely small
extrinsic and
factor of
fails to
fair comparison
faithfully resulting
fan et
favorable as
few labeled
few words
figure algorithm
figure illustrates
figure the
figure words
fills the
fine tune
fine tuned
finetuning the
first example
first fit
first is
first method
first present
first randomly
first update
fischer 2017
fit the
fixed and
fixed augmentation
fixed bert
fixed conditional
fixed number
fixed our
fixed proportion
fixed steps
fleuret 2018
focused on
focuses on
follow ren
following wu
for adaptive
for augmentation
for automated
for certain
for consistency
for fair
for images
for imdb
for inducing
for label
for manipulating
for manipulation
for our
for parameterization
for resnets
for selecting
for sst
for striking
for substitution
for training
for validation
for word
formally let
formulation for
formulation of
formulation we
forth recent
framework in
framework it
framework tan
free parameters
frequency or
from around
from cifar10
from distinct
from table
from validation
full test
function in
function instantiates
function rφ
function since
function we
functions instead
further create
further introduce
further shows
gans baluja
general algorithm
generality for
generate substitutions
generates entire
generating useful
generation can
generation problems
generator respectively
gets more
giridhara et
given an
given set
given the
gpus and
gradient all
gradient descent
gradient for
gradient is
gradient propagation
gradient through
greatly improves
grey antiseptic
grey are
gtx 1080ti
guess this
gumbel softmax
hard example
harm the
harms the
has 210
has 270
has 40
has 90
has become
has crucially
has typically
has used
have alleviated
have been
have developed
have different
have limited
having been
help with
helpful to
hence the
heuristic based
heuristic rules
heuristicbased methods
highest probabilities
hinder model
historical information
however the
idea of
if gφ
if the
illustrates the
image data
image or
image we
imagenet pretrained
imagenet we
images include
imbalance ratios
imbalanced classification
imbalanced ranging
imbalanced sst
imdb 40
imdb as
imdb for
imdb has
implementation of
implemented with
importance experiments
impressive results
improve over
improved learning
improvement over
improvement showing
improves the
in 20
in algorithm
in all
in effect
in figure
in instead
in is
in kobayashi
in minibatch
in modern
in more
in noisy
in our
in parentheses
in part
in presence
in previous
in principle
in reinforcement
in respective
in rφ
in section
in sentence
in simple
in terms
in total
in two
in uniform
in vision
inaccurate and
include cropping
included in
includes 40
including sst
increases as
increasingly ubiquitous
indeed the
indicates the
induce the
induces sample
inducing curriculum
inducing data
infinite in
information which
initial learning
initialize model
initialized as
initialized randomly
initialized with
initializing the
input and
input the
inspired from
instance focuses
instance of
instance to
instances has
instances of
instantiate and
instantiate distinct
instantiate our
instantiate the
instantiated data
instantiated to
instantiates different
instantiating the
instantiations augmentation
instead formulate
instead the
interest as
interest to
interesting perspective
interestingly the
intrinsic rewards
introduce reward
introduced an
introduces lots
intuitively the
investigate the
involves data
is achieved
is again
is applicable
is backpropagated
is beneficial
is better
is built
is configuration
is degenerated
is derived
is enough
is first
is inspired
is negative
is now
is omitted
is prior
is randomly
is reduced
is ren
is retrofitted
is rich
is sample
is set
is solved
is state
is straightforward
is summarized
is that
is unaware
is updated
is widely
is zheng
it also
it has
it matches
iteration based
iteration experiments
iteration ren
iteration the
iteration we
iteratively updated
ith example
its fine
its simplicity
jang et
jiang et
joint data
joint distribution
joint learning
joint manipulation
joint rewards
just different
katharopoulos and
keeps the
key difference
kl is
ko et
krizhevsky et
kullback leibler
kumar et
label and
label denote
label preservation
label preserving
labels and
labels both
labels code
labels faithfully
labels for
labels is
labels per
lack of
largely define
lastly we
latest model
latest weighting
lead to
learn data
learn different
learned in
learned jointly
learned model
learning by
learning clearer
learning compared
learning consistently
learning deep
learning especially
learning kumar
learning model
learning pipelines
learning ratner
learning ren
learning rl
learning section
learning systems
learning there
learning we
learning weighting
learning with
learns augmentation
learns separate
learns text
leibler divergence
lemley et
less studied
let denote
let dv
let pθ
let rin
leveraged validation
li and
likelihood objective
likelihood on
limited application
limited data
limited improvement
line of
linux machine
list the
literature compared
literature in
lm augmentation
lm data
lm eq
lm for
lm instead
lm jointly
lm on
lm parameter
lm such
lm to
log pθ0
log φi
loss recent
lots of
low quality
maas et
machine with
maintained and
maintained throughout
make better
make substitutions
make the
makes data
makes label
malisiewicz et
manipulate data
manipulating data
manipulating small
manipulation and
manipulation are
manipulation either
manipulation formulation
manipulation function
manipulation has
manipulation have
manipulation in
manipulation involves
manipulation on
manipulation reward
manipulation solid
manipulation tend
manipulation that
manipulation the
manipulations and
manually augmenting
manually specified
masked for
masked positions
masked sentence
masked tokens
masks out
matches data
matches different
matches training
matching condition
materials and
maximizing data
maximizing the
measure in
measure of
mechanism can
mechanism has
merged training
method consistently
method first
method in
method is
method of
method outperforms
method showing
method sometimes
method we
methods are
methods on
methods respectively
methods specifically
methods that
miller 1995
minibatch examples
minibatch stochastic
minimizes the
mining shrivastava
mirroring rotation
mirza and
model based
model being
model by
model can
model devlin
model in
model increases
model lm
model of
model parameters
model performs
model pretrained
model seems
model selection
model since
model sst
model states
model this
model through
model to
model trained
models and
models even
models for
models such
modern machine
more broadly
more carefully
more coherent
more concretely
more detailed
more details
more imbalanced
more smoothly
more suitable
more types
more validation
moreover in
most present
movie review
mstep maximizes
names indicates
natural idea
natural objective
negative infinite
network by
network fixed
network to
networks as
networks for
networks such
neural networks
new approach
new instances
new relaxed
new sample
new words
next step
next study
noise during
noisy augmented
normalization in
normalization term
not fit
not in
not observe
not pretrained
notations used
notations with
note that
notpretrained denotes
novel contextual
novel marriage
now demonstrate
now develop
now reduced
numbers in
objective here
objective maximizes
objective of
objective on
observation further
observe significant
observed in
observed that
of 1e
of 4e
of adaptive
of adaptively
of and
of around
of augmentation
of both
of cifar10
of class
of constant
of diverse
of each
of enabling
of epoch
of examples
of existing
of extrinsic
of held
of interest
of is
of manipulations
of meta
of model
of most
of namely
of noise
of notations
of only
of previous
of reformulating
of research
of reward
of rδ
of rφ
of text
of treating
of validation
of very
of we
of words
omitted as
omitted here
on 20
on all
on automated
on binary
on both
on different
on each
on end
on enriched
on imagenet
on images
on imdb
on large
on linux
on model
on original
on particular
on sst
on their
on thus
on training
on various
on we
once we
only in
only limited
only very
only when
operators with
optimal results
optimization consider
optimization for
optimization framework
optimization is
optimization perspective
optimization procedure
optimization with
optimize by
optimize in
optimize on
optimizes intrinsic
or augmenting
or datasets
or generator
or in
or is
or learning
or loss
or replacing
or substitutions
or weighting
or with
org and
original framework
original sentence
original task
original words
osindero 2014
other cases
other comparison
other than
others chang
others sennrich
our adaptive
our algorithm
our automated
our base
our context
our instantiated
our proposed
our weight
our work
ours 36
ours 38
ours fine
out few
out set
outperform variety
outperforms the
output for
output learned
over 20
over weighting
paced learning
paradigm of
paradigms results
parameter and
parameter effectively
parameter is
parameter learning
parameter since
parameter updates
parameterization and
parameterizations for
parameterizations of
parameterizations other
parameterized in
parameterizing rφ
parameters intuitively
parameters of
parameters text
parameters that
parameters to
parametric intrinsic
parentheses next
park et
part or
particular instead
particular interest
particular manipulation
particular parameterizations
particular relevance
particular study
particular the
pass and
pass dashed
peng et
performance and
performance as
performance it
performance over
performance sst
performed on
performs better
perspective data
perspective due
perturbs examples
pick an
picking 40
plugging in
plugging rw
point in
points each
points to
policy gradient
policy is
policy parameter
policy that
policy where
popular benchmark
pose significant
positions with
potentially help
powerful pretrained
practical implementation
practice when
predict sample
predicted by
predicted with
predicted words
presence of
present learning
present machine
present slightly
present the
preserving transformations
pretrained column
pretrained language
pretrained networks
pretrained not
pretraining data
previous manipulation
previous methods
previous weight
principle adopt
prior uniform
probabilities by
probable substitution
probable word
problem is
problem setting
problem where
problems here
problems of
procedure is
proceeds through
process by
processing on
propagation through
proportion 57
proportion 72
proportion method
proposed approach
provide historical
provides only
provides the
providing training
published upon
pytorch org
pytorch pytorch
pθ and
pθ regularized
pθ variational
pθ where
pθ which
quality datasets
quality of
question types
ram all
random guess
randomly initialized
randomly masks
randomly or
randomly picking
randomly select
ranging from
rare classes
ratios we
re estimates
re estimating
reason we
receive unit
receives unit
recent connection
red arrows
reformulating maximum
regardless of
regime or
regularized by
related work
relax the
relaxed reward
relaxing the
relevance to
relevant work
replace rδ
replaces words
replacing the
replacing word
replacing φi
report the
reported results
research on
resnets we
respective classes
respective colors
respective comparison
respectively comparing
respectively in
respectively lastly
respectively the
restricted to
restrictions of
resulting algorithms
resulting model
results by
results however
results indeed
results moreover
results our
retrofitted as
return valid
return varying
review sentiment
reward achieved
reward and
reward can
reward enriched
reward eq
reward even
reward extrinsic
reward free
reward in
reward into
reward is
reward only
reward parameter
reward that
reward the
reward under
reward when
reward with
rewards and
rewards through
rich line
rich types
rl and
rl for
rotation krizhevsky
roth 2002
rule and
rule or
rules do
runs one
rδ dv
rδ equals
rδ in
rδ with
rφ as
rφ in
rφ instead
rφ that
rφ the
rφ which
same number
same processing
sample by
sample importance
sample matches
sample not
sample receives
samples and
samples are
samples for
samples from
samples so
samples to
samples weights
sampling substitution
scale corpus
scale pretrained
scale pretraining
scale unlabeled
scheme alternatively
schemes also
schemes for
schemes the
schemes we
scopes our
scratch at
scratch previous
second is
section as
section due
section we
see from
see our
see the
seems to
select 000
select class
select the
selected in
selected subsets
selecting steps
self paced
sennrich et
sentence and
sentence class
sentence is
sentence label
sentence sentiment
sentence specifically
sentiment maas
sentiment socher
sequence generation
set and
set enriched
set for
set formally
set gradient
set instead
set to
set validation
set we
sets are
sets as
sets the
setting for
setting given
setting specifically
setting the
setting where
settings in
settings of
settings there
settings with
setup for
setup we
sgd optimization
shannon entropy
show improved
show significantly
show two
showcase data
showing that
showing the
shows equivalence
shows superiority
shows that
shrivastava et
signals are
significant challenges
significantly improved
significantly improves
simard et
similarly create
similarly our
simple yet
since as
since every
since our
since text
single algorithm
size the
slightly adapted
slightly more
small amount
small data
small fitting
small set
small size
small thus
small training
small validation
smoothly and
so that
softmax normalization
softmax over
softmax φi
solid arrows
solved with
some previous
sometimes harm
sometimes harms
special instance
specialized reward
specific manipulation
specific types
specifically for
specifically from
specifically given
specifically on
specifically the
specifically we
specified approaches
speculate that
speech ko
speech kobayashi
sst 40
sst for
sst imbalanced
sst sentiment
sst task
sst the
sst with
staged it
state further
state let
state of
states during
step using
step we
steps fails
steps our
steps selected
steps which
still be
stochastic optimization
straightforward to
strict matching
striking in
striking with
strong pretrained
strong restrictions
studied automated
studied in
studied various
study conventional
study different
study we
stunning is
sub optimal
subsample small
subsets for
substitution and
substitution for
substitution section
substitution the
substitution words
substitutions and
substitutions of
substitutions predicted
substitutions that
success such
such extremely
suitable for
suitable technique
sum of
summarized in
superior performance
superior results
superior to
superiority over
supplementary materials
supports learning
synonym 32
synonym approach
synonyms and
synonyms using
synthesis generates
synthesis in
synthesis which
synthesis with
systems has
table also
table that
takes action
taking the
task by
task data
task datasets
task has
task or
task reward
tasks for
technique than
tend to
tends to
term with
terms of
test set
tested the
text contextual
text samples
text transformation
than data
than eq
than weighting
that additive
that augmentation
that data
that different
that enables
that even
that fine
that has
that instantiate
that keeps
that learns
that once
that optimizes
that our
that replaces
that samples
that some
that supports
that takes
that treats
that very
that weights
that were
the 50
the actual
the algorithms
the amount
the art
the augmentatin
the augmented
the average
the best
the boxes
the cases
the cifar10
the combination
the commonly
the computation
the conditioning
the context
the conventional
the distance
the empirical
the end
the engineering
the equation
the equivalence
the established
the expectation
the expected
the expressive
the full
the future
the generality
the highest
the image
the imbalanced
the improvement
the initialization
the input
the ith
the kullback
the lack
the large
the latest
the log
the marriage
the method
the minibatch
the models
the most
the mstep
the normalization
the notations
the numbers
the output
the paper
the parameter
the popular
the practical
the predicted
the pretrained
the process
the rare
the relevant
the resnet
the respective
the samples
the selected
the sentence
the single
the size
the state
the strict
the strong
the sum
the supplementary
the text
the three
the top
the true
the use
the value
the vanilla
the varying
the weighted
the word
their gradient
their synonyms
then adding
then fed
then fixed
then used
then written
there are
there is
these algorithms
these learning
this can
this perspective
this section
though having
though more
though the
three datasets
through efficient
through finetuning
through novel
thus adapt
thus beneficial
thus can
thus favorable
thus omitted
thus the
thus we
to adapt
to additionally
to any
to assign
to augment
to automatically
to avoid
to be
to bert
to boost
to build
to connect
to create
to cubuk
to different
to diverse
to each
to empirically
to enable
to excel
to expand
to explore
to fit
to generate
to hinder
to induce
to instantiate
to investigate
to its
to just
to manipulate
to maximum
to our
to over
to perform
to predict
to relax
to respective
to see
to show
to significantly
to specialized
to sub
to this
to through
to use
to vision
tokens striking
too small
total while
train data
train on
trained models
trained on
trained to
training epoch
training for
training instead
training it
training loss
training previous
training proceeds
training sample
training samples
training sets
training signals
training significantly
tran et
transformation functions
transformation network
transformations on
transformer or
transforms the
translation sennrich
treated as
treating data
treatment achieves
treatment can
treatment is
treats data
treats the
trec 40
trec for
trec has
trec is
trec respectively
tried fitting
true label
tune the
tuned augmentation
tunes an
tunes the
tuning text
tuning the
tuning we
two difficult
two distinct
two manipulation
two masked
two paradigms
two parameterizations
two particular
two samples
two settings
two tokens
two types
two ways
type data
type of
type we
types li
types than
typically focused
ubiquitous to
unaware of
uncased model
under and
uniform distribution
uniform way
unlabeled data
until convergence
update depends
updated instead
updated throughout
updated to
updated with
updates our
updating the
upon acceptance
upon recent
upon which
use 10
use both
use efficient
use gumbel
use large
use new
use only
use reinforcement
use resnet
use sgd
use slightly
used especially
used for
used generative
used here
used proportion
used throughout
used we
useful samples
uses fixed
uses held
uses validation
using the
using validation
using wordnet
usual and
valid reward
validating that
validation accuracy
value of
value we
value with
values freund
values when
variational distribution
variational policy
various manipulation
various problems
various rule
various settings
various ways
vary the
varying data
varying imbalance
varying reward
verify our
very few
very helpful
very limited
very small
via meta
vision and
vision simard
visually striking
was derived
way natural
ways resulting
ways the
we approximate
we are
we augment
we automate
we choose
we could
we devise
we discuss
we draw
we evaluate
we follow
we formulate
we further
we have
we instead
we learn
we next
we observe
we optimize
we pick
we propose
we randomly
we replace
we report
we select
we showcase
we similarly
we speculate
we subsample
we thus
we train
we update
weight associated
weight learning
weight ren
weight value
weighted sampling
weighted update
weighting approach
weighting assigns
weighting boost
weighting data
weighting has
weighting in
weighting mechanism
weighting methods
weighting network
weighting performs
weighting provides
weighting respectively
weighting scheme
weighting that
weighting to
weighting which
weighting with
weights adaptively
weights as
weights by
weights our
weights ren
weights respectively
weights this
weights using
well due
well in
well on
were implemented
when is
when it
when minibatch
when sample
when sampling
when updating
where only
where since
where various
where φ0
where φi
which are
which creates
which fills
which includes
which learns
which makes
which optimizes
which our
which powerful
which uses
which we
while for
while imdb
while on
while the
while weighting
widely used
will be
with above
with base
with being
with bland
with eq
with factor
with gtx
with imagenet
with imbalanced
with large
with learning
with log
with model
with or
with parameters
with policy
with pretrained
with pytorch
with reinforcement
with rφ
with synonyms
with their
with variety
with various
with varying
without changing
word striking
word substitution
word substitutions
word with
wordnet miller
words after
words from
words in
words predicted
words replacing
words the
words to
work by
work each
work jiang
work kobayashi
work ren
work upon
work wu
write as
written as
yet general
yielding data
yields accuracy
φ0 is
φi cancels
φi if
φi is
08 86
100 1000
1000 100
1000 50
15 runs
20 1000
2016 and
2018 74
2018 our
2018 these
2018 which
2018 wu
2019 ratner
2019 that
34 he
40 instances
40 training
50 1000
accuracy of
accuracy points
adapt its
adaptive data
adapts an
additionally fine
advantage of
aim to
al 2013
al 2017
algorithm can
algorithm for
algorithm our
algorithms such
an importance
an off
analogue to
and alternatingly
and are
and data
and image
and imbalanced
and instances
and is
and manipulation
and others
and schapire
and speech
and text
and thus
and trec
and use
and validation
and weighting
applicable to
approach for
approach is
approach that
are reduced
are usually
argmaxθ ep
arrows denote
as above
as bert
as in
as policy
as reward
as the
augmentation and
augmentation as
augmentation has
augmentation lm
augmentation model
augmentation network
augmentation we
augmentation wu
augmented samples
automated data
averaged over
base models
based approaches
based augmentation
based on
based reward
be the
because the
been increasingly
bert devlin
bert lm
better than
binary classification
both the
by inverse
by maximizing
by taking
by the
can directly
can return
can write
class and
class for
class frequency
class imbalance
classification performance
classification the
classification we
compare with
compared to
comparison methods
composition of
conduct extensive
consistently improves
context of
contextual augmentation
create small
cubuk et
data and
data examples
data for
data in
data log
data points
data regime
data reward
data setting
data synthesis
data used
data we
data which
degenerated to
demonstrate the
denote learning
denote the
depends on
designed for
devlin et
different data
different manipulation
different parameterization
different types
due to
during augmentation
each class
each data
each iteration
each of
effect on
efficient stochastic
enable efficient
enriched with
entire artificial
ep exp
epoch and
eq 11
eq and
eq we
equivalence between
especially in
estimated from
ex in
examples in
examples the
exp rδ
experiments show
extensive experiments
extrinsic reward
fine tunes
fine tuning
first row
fit to
fitting the
for binary
for both
for class
for data
for different
for each
for example
for fixed
for image
for joint
for learning
for specific
for the
formulate manipulation
freund and
from scratch
from the
function and
function of
function reward
gradient based
gradient directions
has also
has been
has developed
has studied
has the
he et
held out
here we
image classification
imbalance problems
imbalanced cifar10
imbalanced data
imbalanced labels
imdb and
importance weight
improve model
improve the
improved performance
improves over
in analogue
in contrast
in different
in epoch
in eq
in low
in particular
in practice
in ren
in supervised
in text
in that
in this
in various
in which
increasingly used
inspiration from
instances and
instances for
instances in
instances per
instantiation of
interesting to
into eq
intrinsic reward
inverse class
is also
is an
is function
is interesting
is then
is thus
is to
is used
is we
is worth
its effect
joint training
jointly with
kobayashi 2018
label conditional
labeled examples
language model
large scale
learn the
learning algorithm
learning and
learning as
learning based
learning data
learning different
learning for
learning is
learning manipulation
learning of
learning rate
learning the
likelihood learning
likelihood of
lm is
log likelihood
log pθ
machine learning
manipulation approach
manipulation as
manipulation can
manipulation for
manipulation is
manipulation learning
manipulation methods
manipulation parameter
manipulation parameters
manipulation rφ
manipulation type
manipulation types
marriage of
maximize the
maximizes the
maximum likelihood
meta learning
method that
methods we
minibatch by
model 20
model and
model bert
model for
model is
model on
model parameter
model performance
model pθ
model resnet
model val
model we
models are
models we
most probable
network and
network jointly
new method
next section
next to
noting that
number of
objective is
observe that
obtain the
of different
of learning
of low
of manipulation
of our
of particular
of policy
of re
of steps
of supervised
of target
of training
off the
on image
on imbalanced
on learning
on text
on validation
one standard
only the
optimize the
optimizes and
original data
our augmentation
our data
our method
ours 75
out validation
over 15
over strong
over the
parameter in
parameterization of
parameters maintained
parametric treatment
per class
perform well
performance in
performance measure
performance of
performance on
performs best
perspective of
points on
policy optimization
policy we
preserve the
pretrained on
pretrained weights
proportion based
propose new
rate of
ratner et
re estimated
recent work
reduced to
regime and
reinforcement learning
resnet 34
resnet he
resulting algorithm
resulting in
results are
results of
results on
results table
reward rφ
row shows
rφ can
same algorithm
sample weights
schapire 1997
schemes are
schemes with
scratch in
set of
set our
sets for
shelf reward
show in
show the
significantly improve
since the
size data
small subset
socher et
sst and
standard deviation
step is
stochastic gradient
striking and
strong base
study on
study the
subset of
supervised learning
supervised setting
table accuracy
table shows
tan et
text and
text augmentation
than ren
that are
that dynamically
that is
the advantage
the algorithm
the approach
the bert
the class
the classification
the composition
the dataset
the exact
the first
the fixed
the function
the gradient
the heuristic
the instantiation
the intrinsic
the joint
the labels
the literature
the low
the manipulation
the masked
the maximum
the new
the next
the number
the objective
the original
the parametric
the policy
the previous
the problem
the proportion
the recent
the resulting
the results
the reward
the same
the second
the shelf
the small
the softmax
the sst
the step
the target
the task
the two
the ultimate
the update
the validation
the weight
the weights
then to
this is
this work
through eq
throughout the
to both
to eq
to improve
to learn
to make
to maximize
to optimize
to preserve
to train
to when
train the
training and
training data
training different
training example
training examples
training instances
training of
training set
training validation
training we
two classes
types of
ultimate performance
unit reward
update for
update is
update the
use of
use the
used in
used to
usually designed
val data
validation data
validation examples
validation instances
validation sets
vanilla maximum
variety of
various algorithms
we aim
we also
we can
we compare
we conduct
we demonstrate
we first
we instantiate
we now
we obtain
we present
we show
we study
weight to
weighting and
weighting by
weighting for
weighting is
weighting method
weighting on
weighting results
weighting we
weights are
weights based
weights in
weights more
weights of
where is
where the
which can
which in
which is
with an
with data
with new
work has
work is
work tan
work we
worth noting
wu et
xie et
zheng et
al 2016
al 2019
and the
base model
can be
data augmentation
data weights
for text
in each
in the
instead of
is the
it is
low data
manipulation schemes
model training
of data
on the
our approach
previous work
ren et
reward function
reward learning
shows the
such as
target model
text classification
text data
that the
the above
the augmentation
the base
the data
the lm
the model
the training
to the
validation set
we use
with the
al 2018
data manipulation
data weighting
et al
of the
