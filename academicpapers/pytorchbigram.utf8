zero note
years there
yaml meta
xeon e5
written in
writing models
writers usually
write to
write cuda
would struggle
would negate
would let
worse is
workstation with
works and
working on
workflows defining
work together
work such
work quickly
work queue
work on
work is
work has
work done
work as
word pytorch
without sacrificing
without knowing
without further
without any
with two
with this
with the
with tensor
with standard
with several
with respect
with pytorch
with python
with packages
with other
with one
with more
with lush
with large
with implicit
with for
with fairly
with external
with explicit
with eager
with careful
with body
with automatic
wise it
will occur
will have
will empower
will be
whose forward
whole design
whole computation
while we
while this
while there
while still
while remaining
while most
while maintaining
while allowing
which takes
which specify
which queues
which more
which limits
which lets
which is
which incrementally
which in
which does
which computes
which can
which builds
whether its
where they
where python
when tensors
when dealing
were performed
well this
well the
well as
weaving previous
weaker resulting
we used
we use
we tried
we start
we show
we report
we plan
we have
we expect
we emphasize
we detail
we demonstrate
we counted
we could
we compare
we chose
we can
we attribute
we are
we always
we also
way to
way that
way of
way listing
was tuned
was to
was pioneered
was last
want to
wait for
vital to
visualization tools
visibility into
vibrant communities
via automatic
vgg 19
very popular
versioning system
version of
vectorjacobian product
vast repository
various operators
various machine
various benchmarks
varied numerical
vancouver canada
value of
validity of
v4 cpus
utils data
utilizing other
utilized the
utilize techniques
utilize reference
utilize all
utilization of
utilization in
utilities that
utilities are
usually take
usually resort
usually represented
usually beneficial
using yaml
using the
using less
using forwardmode
using array
using all
using 32bit
uses the
uses of
uses multiple
users was
users to
users often
users leverage
users in
users do
users can
users are
users and
user we
user unless
user to
user programs
user from
user error
user defined
useful pytorch
used to
used the
used on
used objects
used in
used for
used deep
used as
use trading
use there
use the
use on
use of
use more
use model
use is
use ease
use case
usage patterns
usability with
usability or
usability centric
us track
us to
us state
us saturate
update generator
update discriminator
up with
up to
up the
up representation
up fragmented
up cache
up allocations
up all
unwanted behaviors
until all
unless they
unique feature
understand how
underlying memory
under the
uncommon feature
unacceptable in
typically expressed
typical way
types of
two separate
two methods
two loss
two intel
two goals
two events
turned out
turned multidimensional
tuned for
triggers to
tried to
trends in
trends by
trends and
treat memory
transparently handles
training techniques
training step
training speed
training process
training of
training iteration
training and
trading 10
tradeoff is
tracks both
track their
track the
traces of
trace the
trace of
towards the
torchscript engine
torch7 utilized
torch7 25
torch utils
torch randn
torch multiprocessing
torch mm
torch jax
torch from_numpy
torch eigen
torch dynet
torch autograd
top row
top priorities
top of
tools that
tools pytorch
tools offload
tools mentioned
tools many
tools like
tools including
tool in
tokens per
together to
to write
to work
to wait
to utilize
to use
to treat
to track
to trace
to three
to this
to the
to take
to support
to structure
to sprinkle
to specify
to source
to shared
to rewrite
to restructure
to reproduce
to replace
to quickly
to queue
to quantify
to preserve
to perform
to overlap
to other
to optimize
to not
to new
to multivariate
to multiples
to multiple
to monolithic
to measure
to manually
to manipulate
to manage
to make
to maintain
to machine
to leverage
to later
to just
to jumpstart
to interpret
to instrument
to improve
to impose
to implementations
to implement
to hold
to highlight
to have
to handle
to further
to fully
to find
to experiment
to execute
to exchange
to ensure
to easily
to do
to deliver
to deep
to custom
to create
to convert
to continuing
to continue
to classify
to certain
to be
to batches
to avoid
to automatically
to asynchronously
to as
to also
to alleviate
to all
to add
to achieve
to account
times longer
times in
timeline of
time would
time this
time source
time saved
time rigid
time no
time machine
time it
time hence
time deep
time and
throughput is
throughput higher
throughout the
through code
three times
three popular
threads to
threads is
threaded programs
thread for
thread communication
those that
those operators
those operations
those criteria
those can
this use
this to
this technique
this task
this system
this solution
this setup
this setting
this section
this result
this problem
this path
this paper
this mechanism
this made
this lets
this interface
this growing
this fulfilled
this facilitates
this exchange
this example
this everything
this ensures
this effect
this design
this define
this count
this core
this combination
this bottleneck
this automatically
this approach
this allows
this allocator
third with
things it
they likely
they implement
they can
they are
these work
these two
these trends
these tools
these overheads
these hardware
these deep
therefore to
therefore its
therefore it
therefore critical
there is
there has
there are
theoretically be
then be
then allocated
themselves evolved
them to
them the
them that
them separately
them know
them hence
them cooperatively
their python
their project
their programs
their parameters
their own
their models
their impact
their code
theano construct
theano are
the work
the word
the whole
the very
the vectorjacobian
the value
the validity
the utilization
the users
the user
the use
the underlying
the typical
the types
the training
the torchscript
the torch
the top
the tensor
the system
the steps
the state
the speed
the specific
the simple
the search
the scientific
the scarcity
the same
the runtime
the rich
the result
the resolution
the resnet
the research
the really
the reallocation
the pytorch
the python
the program
the process
the problem
the principles
the primitives
the potential
the performance
the overall
the operators
the operator
the operations
the openness
the open
the one
the nvidia
the numerical
the number
the new
the neural
the network
the needs
the ncf
the monthly
the models
the memory
the machine
the libtorch
the library
the length
the latest
the key
the internal
the initial
the indexing
the incremental
the increased
the implementation
the imperative
the host
the gray
the gradient
the gpus
the gpu
the gnmtv2
the global
the generator
the garbage
the game
the future
the function
the full
the freed
the free
the floating
the first
the field
the features
the fastest
the fast
the familiar
the fact
the experimentation
the expense
the existing
the execution
the exact
the evaluation
the efficiency
the dynamic
the dlpack
the discriminator
the device
the development
the desired
the deep
the deallocation
the daunting
the dataloader
the data
the cudnn
the cudafree
the cuda
the critical
the cpu
the costs
the cost
the corresponding
the converted
the control
the construction
the computing
the computed
the computation
the complexity
the communication
the commonly
the colored
the careful
the built
the bottom
the benchmarks
the behavior
the basic
the average
the availability
the automatic
the autograd
the arrows
the appendix
the allocator
the allocations
the advent
the ability
the 1960s
that would
that we
that way
that users
that this
that they
that these
that the
that supports
that shows
that represents
that pytorch
that performance
that operate
that only
that of
that nothing
that no
that mention
that memory
that it
that implements
that every
that enabled
that either
that ecosystem
that drove
that does
that do
that depend
that compose
that combine
that can
that balances
that any
that allows
that allow
than python
than inputs
than cpu
than comprehensive
tensors which
tensors using
tensors sent
tensors into
tensors become
tensors and
tensorflow to
tensorflow and
tensorflow 1422
tensor to
tensor operators
tensor operations
tensor method
tensor memory
tensor data
tensor computations
tensor and
tensor allocator
techniques like
technique of
technique for
tasks all
task on
taking up
takes great
takes different
takes around
take the
take significant
take constant
take advantage
table training
table on
t3 self
t2 torch
t2 nn
t2 def
t1 torch
t1 self
systems neurips
systems are
system to
system is
system for
system allows
synchronize gradients
synchronization would
synchronization to
synchronization is
swift but
susceptible to
surprisingly short
supports code
supported by
support this
support the
support for
support arbitrary
super __init__
summarized in
suite of
such as
such an
success stems
subtle and
subsystems as
subsequent ones
subsequent iterations
submissions mentioning
subclassing torch
subclass of
style primitives
style high
struggle with
structure their
structure the
strives to
strict separation
streams serialize
streams it
stream work
stream design
stream but
stream as
stream and
still allowing
steps needed
step real_sample
stems from
statistical analysis
static dataflow
statements standard
stateful functions
state of
state again
starts reusing
starting with
starting in
start running
start by
starcraft 36
starcraft 28
standard plotting
standard multiprocessing
standard debuggers
sprinkle the
speeding up
speed of
speed for
speed but
speed and
specify the
specified by
specifically to
specific memory
specific languages
specialized memory
specialized libraries
source to
source python
source differentiation
some recent
solved the
solution than
solution ensures
software such
software movement
software fostered
software for
softmax to
softmax t3
so while
so the
so on
so either
slow down
slightly incomplete
skill to
sizes is
situations and
single training
single machine
since the
since streams
since pytorch
since gradient
since 2014
simultaneously empowering
simplifies the
simplified training
simplicity and
simpler to
simple sequences
simple it
simple design
simple can
simple but
simple and
similarly new
similarly models
similar mechanism
similar functionality
significantly from
significantly easier
significant amount
sidestep this
sides only
side effects
side effect
shuffling batching
shows the
shows that
shows representative
shown in
show an
should really
should be
short amount
sharing of
shared memory
share the
several other
several common
setup but
setting as
set of
serialize execution
serialization used
sequences of
sequence of
separation between
separately libraries
separate models
separate control
sent to
sense of
sending it
semantics have
self t3
self return
self nn
self in_sz
self fc
self conv
self activations
seems limiting
section we
second the
second for
search case
scripting languages
scipy 19
scientists are
scientific computing
scientific community
scheme to
scheduling the
scheduling is
scarcity of
scarce resource
scale images
scalar output
scalability of
scalability however
saved by
saturate the
satisfy those
samples per
same version
same time
same stream
same order
same form
safety we
sacrificing performance
rust bindings
runtime periodically
runtime making
runtime enables
runtime as
runs ahead
running their
running optimizers
running on
running deep
running at
run it
run framework
run either
run approach
row shows
row depicts
rounds up
rigid apis
rich offering
rich ecosystem
rewrite their
reverse mode
reusing previously
reusable deep
return self
return nn
results are
resulting in
result to
result of
result in
restructure the
respect to
resources and
resource that
resort to
resolution of
resnet 50
resembles regular
researchers while
researchers first
research hence
research community
requirements of
required by
require holding
reproduce our
represents the
represented as
representative timeline
representation of
repository of
report the
replacement for
replace any
repeatedly to
remote procedure
remaining efficient
rely on
relu t1
relies on
releasing brand
released exactly
release of
relative performance
regular threaded
regular python
region which
reflected in
referred to
references made
references internal
reference counting
reduce style
recursive functions
record timeline
recognizing individual
recognized the
recent years
received pytorch
reassigns it
really complicated
really be
reallocate memory
real_sample real_label
reaches zero
reach peak
ratio depends
rapidly from
range of
randn out_sz
randn in_sz
quite dramatically
quickly outpaces
quickly create
quickly address
queues the
queued work
queue various
queue cuda
quantifying the
quantify how
quadro gp100
pytorch with
pytorch uses
pytorch tracks
pytorch to
pytorch that
pytorch tensors
pytorch takes
pytorch such
pytorch success
pytorch strives
pytorch solved
pytorch simple
pytorch should
pytorch python
pytorch programs
pytorch performs
pytorch operators
pytorch on
pytorch needs
pytorch must
pytorch most
pytorch model
pytorch maintains
pytorch library
pytorch jit
pytorch is
pytorch in
pytorch implements
pytorch has
pytorch for
pytorch extends
pytorch easily
pytorch could
pytorch can
pytorch caching
pytorch by
pytorch builds
pytorch because
pytorch as
pytorch an
pytorch almost
pytorch allows
pytorch 1547
pythonic programming
pythonic library
pythonic data
python using
python this
python starting
python programs
python program
python packages
python own
python note
python made
python lisp
python library
python libraries
python language
python is
python interpreter
python interface
python global
python ecosystem
python default
python community
python code
python classes
python bindings
python are
python and
pypy or
put researchers
purpose programming
purpose massively
purpose languages
providing tools
providing efficient
providing an
provides visibility
provides the
provides automatically
provides an
provided the
provided by
provide pragmatic
proprietary software
project they
progress in
programs we
programs users
programs to
programs that
programs hence
programs execute
programs and
programming style
programming productive
programming model
programming language
program with
program under
program to
program this
program philosophy
program branches
profiler to
profiler 44
productive in
productive as
production oriented
product similarly
processing tools
processing systems
processes to
processes and
process therefore
process print
process isolation
process communication
process are
process an
procedure calls
problem the
problem differently
problem by
priorities for
prior work
prints since
print statements
principles that
principles behind
primitives uses
primitives or
primitives it
primitives for
primitives all
previously queued
previously allocated
previous ideas
prevent the
preserve the
preprocessing statistical
precedes the
pragmatic performance
pragmatic implementation
practice pytorch
practice kernel
practical code
power required
potential neural
potential benefits
possibly lazy
possible to
possible the
possibility to
popularized the
popular tool
popular scientific
popular in
popular graph
popular generative
popular frameworks
pool per
pool of
point computations
plotting debugging
plotting and
playing starcraft
platforms it
platform paddlepaddle
plan to
places where
pioneered for
pinned cuda
philosophy is
persistence which
periods of
periodically investigates
performs reverse
performs immediate
performed on
performed hence
performance wise
performance to
performance this
performance reusable
performance requirements
performance of
performance in
performance focused
performance even
performance considerations
performance comparable
performance cliffs
performance characteristics
performance and
performance additionally
performance across
perform forward
perfect device
percentage of
per stream
per second
peak performance
patterns of
path as
particular solution
part of
parameters are
parameters and
parameter t2
parameter t1
parallelizing the
parallelization and
parallelism based
parallelism as
parallel to
parallel programs
parallel primitives
parallel hardware
papers each
paper we
paper only
paper introduces
pandas 20
pair the
paddlepaddle the
paddlepaddle 933
packages like
packages for
package popularized
package and
pace of
own specialized
own reference
own performance
own multi
overloading approach
overlap the
overhead like
overall sense
overall 43
over the
outside of
outputs than
output with
output tensor
outpaces the
out_sz self
out_sz def
out to
our users
our system
our setup
our results
our community
our choices
other than
other python
other processes
other languages
other gpu
other commonly
oriented platform
order will
order to
or using
or tensorflow
or speed
or operators
or on
or more
or if
or changing
optimizing every
optimizers as
optimizers and
optimized we
optimized libraries
optimized code
optimize the
optimization strategies
optimization is
optimg step
optimg optim
optimd step
optimd optim
optim adam
operators to
operators on
operators of
operators is
operators convolution
operators can
operators asynchronously
operators and
operator overloading
operator must
operator making
operator invocations
operator and
operations usually
operations performed
operations of
operations are
operate on
opens the
open source
only one
only once
only guarantee
only describe
ones while
ones at
one training
one stream
one research
one pool
one of
one notable
one needs
one interesting
one idiomatic
once this
once and
on write
on workstation
on usability
on top
on these
on them
on the
on tensors
on several
on reference
on python
on one
on neural
on mobile
on independent
on gpu
on either
on ease
on disk
on cpu
on both
on arxiv
on another
on all
often various
often referred
often focused
often design
often composed
offering of
of vibrant
of vast
of utilities
of user
of use
of torch
of tools
of time
of those
of this
of these
of their
of the
of that
of tensors
of tasks
of such
of subsequent
of static
of speeding
of speed
of single
of simplicity
of side
of shuffling
of serialization
of sending
of scalar
of resnet
of researchers
of pytorch
of python
of progress
of pinned
of performance
of our
of open
of of
of new
of models
of mentions
of memory
of mathematical
of many
of machine
of library
of libraries
of large
of languages
of keeping
of its
of individual
of imperative
of high
of graph
of gpu
of generative
of general
of functions
of free
of feed
of execution
of engineering
of elements
of ease
of each
of dynamic
of domain
of doing
of design
of deep
of debugging
of data
of cuda
of cross
of course
of core
of concurrent
of computing
of computation
of automatic
of any
of all
of academic
of 512
occur on
observed to
objects supported
objects on
objects conforming
objects and
objective and
nvidia quadro
nvidia profiler
numpy tensor
numpy arrays
numpy 12
numerical programs
numbers 31
number of
notoriously hard
notoriously challenging
nothing forces
note that
notably we
notable caveat
not to
not therefore
not satisfy
not require
not pypy
not meet
not limited
not have
not both
not aware
not at
not allow
normalization and
no matter
no copies
nn parameter
nn module
nn functional
nn conv2d
nimtorch 34
new training
new subclass
new situations
new potential
new or
new ones
new datasets
new allocation
never uses
never exhibits
neurips 2019
neural networks
neural network
neural information
networks themselves
networks one
networks in
network effects
network architecture
negate the
needs to
needs or
needs of
needs by
needed to
needed by
nearly invisible
ncf model
naturally with
mxnet pytorch
mxnet and
mxnet 1554
mutations are
mutation on
must dynamically
must be
multivariate input
multiprocessing which
multiprocessing module
multiplication dropout
multiples of
multiple times
multiple tasks
multiple streams
multiple other
multidimensional arrays
multi stream
moves the
moves rust
movement the
moved away
most of
most notably
most mutations
most importantly
most deep
most built
most behaviors
moreover the
moreover many
moreover it
more outputs
more moreover
more memory
more importantly
more formally
more efficiently
more closely
monthly number
month that
monolithic kernels
module into
module containing
module class
modifications and
modern machine
models using
models to
models the
models specified
models loading
models in
models data
models at
models are
models and
modeling libraries
model works
model which
model the
model parallelism
model of
model makes
model is
model can
model authoring
model as
model and
model accelerated
mode performance
mode differentiation
mode automatic
mobilenet models
mobilenet gnmtv2
mm activations
methods which
methods specialized
methods process
methods __getitem__
method similar
metaprogramming based
meta data
mentions of
mentions among
mentioning pytorch
mentioned on
mention pytorch
mention common
memory without
memory usage
memory to
memory these
memory region
memory overall
memory management
memory is
memory immediately
memory freed
memory for
memory errors
memory available
memory as
memory allocators
memory allocator
memory ahead
member of
meet the
mechanism to
mechanism this
mechanism is
mechanism 38
measured in
measure as
may block
matrix multiplication
matplotlib all
matlab and
mathematical primitives
massively parallel
many users
many scripting
many popular
many of
many loops
manually control
management on
management of
management functions
manage tensor
manage carefully
making it
making datasets
making ahead
makes the
makes debugging
make writing
major trends
maintains strict
maintains distinct
maintaining performance
maintain design
main principles
made the
made it
made by
made array
machine learning
machine eager
lush 14
lua eblearn
lua and
loss functions
loss discriminator
loops and
longer than
long periods
long as
lock gil
lock 33
loading the
loading data
loading and
loaders as
loaders and
lists how
listing simplified
listing demonstrates
listing custom
lisp torch
lisp and
linearlayer module
linearlayer 128
linear sequence
linear layers
limits their
limiting since
limited to
likely want
like python
like possibly
like numpy
like nimtorch
like hogwild
like copy
libtorch library
library that
library provides
library or
library implements
library for
library but
library and
libraries with
libraries while
libraries that
libraries such
libraries for
libraries as
libraries and
libraries 39
leveraging the
leveraged to
leverage the
leverage similar
leverage other
leverage additional
level dual
lets us
lets them
let them
less expressive
less common
lengthy compilation
length operator
learning workflows
learning tools
learning this
learning should
learning research
learning pytorch
learning models
learning methods
learning library
learning libraries
learning kernels
learning in
learning grew
learning frameworks
learning for
learning community
learning approaches
learning applications
learning and
learning algorithms
lazy lists
layers which
layers into
layers composing
layers but
layers are
layer used
launched during
later synchronize
later allocations
last used
last use
largely without
large the
large arrays
languages that
languages such
languages resulting
languages other
language with
language torch
language that
language its
labor of
knowing how
key components
kernels that
kernels launched
kernel writers
kernel invocations
keras mxnet
keeping the
keeping interfaces
keep up
just the
just python
just program
jumpstart one
julia 11
jl 18
jit suite
jax 17
january 2017
its users
its user
its runtime
its results
its programming
its last
its interpreter
its implementation
its existence
its execution
its effectiveness
its derivative
its current
its control
its caller
its architecture
iterator over
iterations as
iteration of
iteration differs
it without
it will
it transparently
it to
it significantly
it rounds
it relies
it provides
it possible
it over
it opens
it needs
it maintains
it is
it has
it follows
it easy
it causes
it can
it an
it also
it almost
it achieves
issues moreover
isolation weaker
is written
is within
is vital
is usually
is used
is therefore
is the
is that
is susceptible
is shown
is shared
is running
is rich
is released
is regular
is one
is notoriously
is not
is needed
is nearly
is more
is measured
is machine
is less
is just
is inefficient
is inconvenient
is hardware
is hard
is handled
is freed
is executed
is even
is dynamic
is drop
is designed
is consistent
is completely
is common
is better
is also
is acceptable
invocations to
invocations on
invisible to
investigates the
intuitive apis
introducing subtle
introduces pytorch
into torch
into the
into lua
into incredibly
into first
into design
into autonomously
interpreter where
interpreter the
interpreter lock
interpreter is
interpreted language
interpret memory
interoperability is
interoperability because
interoperability and
internally by
internal to
internal implementation
intermediate computations
interfaces simple
interface as
interface and
interesting tradeoff
interesting side
interesting and
interest in
interactions with
inter process
intend to
intel xeon
integrating with
integrates naturally
integrated in
instrument various
instead pytorch
instead of
instance the
instance layers
instance 296
insert additional
insensitive to
inputs is
initialize their
initial release
inherent to
information processing
inefficient when
individual subsystems
individual layers
individual digits
indexing operator
independent of
independent gpus
incrementally builds
incremental allocation
incredibly varied
increasingly important
increasing batch
increased interest
inconvenient such
incomplete solution
including the
including caffe
in_sz out_sz
in way
in user
in tokens
in to
in time
in this
in their
in the
in that
in table
in surprisingly
in subsequent
in scientific
in replacement
in recent
in pytorch
in projects
in profiler
in practice
in practical
in places
in parallel
in package
in order
in objective
in multithreaded
in modern
in listing
in lisp
in linear
in languages
in its
in implementations
in images
in given
in general
in functions
in frameworks
in figure
in fact
in each
in deep
in caffe
in both
in bold
in an
in addition
improves the
improves performance
improvements independent
improve the
improve support
improve performance
improve its
impose any
importantly users
importantly intermediate
important for
implicit parameters
implements the
implements forward
implements custom
implementing two
implementer and
implemented versioning
implementations that
implementations of
implementation to
implementation of
implementation does
implementation and
implementation accepts
implementation 30
implement this
implement their
implement the
implement techniques
implement heavily
implement basic
imperative style
imperative programs
imperative and
impact on
immediately once
immediately as
immediate execution
images per
images note
if the
if an
idiomatic way
ideas into
ideally with
iclr 2019
however with
however the
however python
however on
however it
however if
however by
how well
how to
how they
how these
how the
how simple
how model
how large
how it
how an
host cpu
hoping that
holding the
hold the
hogwild 42
higher is
high performance
high overhead
hidden behind
hence while
hence those
hence since
hence pytorch
hence lowering
heavily parallel
have to
have simple
have often
have implemented
have become
hasktorch 35
has turned
has to
has recognized
has good
has established
has been
has become
hardware such
hardware fifo
hardware accelerators
hard to
happens in
handles sharing
handled by
handled automatically
handle this
handle dataset
guarantee the
growing complexity
grew from
greatly improves
great performance
great care
gray scale
gray areas
graph that
graph sidestep
graph metaprogramming
graph based
gradients of
gradient of
gradient formulas
gradient based
gpus provided
gpus hardware
gpus completes
gpus but
gpu we
gpu this
gpu the
gpu synchronization
gpu so
gpu memory
gpu finishes
gpu enabled
gpu by
gpu because
gpu as
gpu and
gpu acceleration
gp100 gpu
goals of
go down
go away
gnmtv2 ncf
gnmtv2 model
global interpreter
given time
given the
given paper
given fixed
gil python
get an
generator parameters
generator get_noise
generator create_generator
generator and
generative adversarial
generated using
general purpose
garbage collector
garbage collection
game engine
future work
future we
future garbage
further use
further improve
functions with
functions to
functions this
functions that
functions cudamalloc
functions composed
functionality provided
functionality of
functionality is
functional softmax
functional relu
function that
function every
function and
fully automate
fullbasicmodel nn
full control
fulfilled most
from weaving
from utilizing
from that
from simple
from recognizing
from python
frees the
frees everything
freed region
freed on
free to
free software
free precedes
free of
frameworks we
frameworks such
frameworks percentage
frameworks implement
frameworks have
frameworks converged
frameworks cntk
frameworks based
framework we
framework throughput
framework chainer
fragmented per
four major
four main
fostered the
forwardmode automatic
forward self
forward mode
forward methods
forward layers
formulas for
format note
formally the
form of
foregoes the
forces the
for various
for user
for the
for tensors
for starcraft
for simple
for significantly
for pytorch
for on
for numpy
for neural
for most
for models
for model
for machine
for long
for lengthy
for instance
for general
for example
for every
for efficient
for each
for distributed
for deep
for data
for custom
for bidirectional
for better
for assignment
follows the
focused on
focused implementation
flux jl
flow running
flow is
flow graph
floats throughput
floating point
flexibility of
fixed amount
first starting
first pytorch
first iteration
first few
first class
first calls
finishes since
find their
find that
find performance
finally we
finally the
files an
figure we
figure trace
figure the
figure shows
figure annotated
figure among
fifo this
field of
few operators
few operations
feed forward
features of
features adapt
feature of
fc t1
fc linearlayer
fastest speed
fastest framework
fastest current
faster language
fast pace
familiar with
familiar concepts
fake real_label
fake generator
fake detach
fairly high
fact torch7
fact that
fact compatible
facilitates the
extremely cheap
external references
external libraries
extensible for
extends this
extends the
extending the
extended to
expressive faster
expressed as
explosion of
explicit triggers
explain how
experiments were
experimentation of
experiment with
expense of
expected users
expect one
existing functionality
exhibits unwanted
execution while
execution takes
execution quite
execution of
execution if
execution for
execution can
executed using
executed outside
executed on
executed in
executed entirely
executed by
execute operators
execute in
execute eagerly
execute dataflow
exchange of
exchange happens
exchange data
exceptions to
example to
example it
example implementation
example gpu
exactly when
exact scheduling
exact ratio
everything is
everything else
every operator
every cuda
every aspect
events in
even possible
even in
evaluator which
evaluation of
essential skill
essential feature
errors go
error which
errg loss
errg backward
errd_real loss
errd_real backward
errd_fake loss
errd_fake backward
equal the
enumerates used
entirely in
entire model
ensures that
ensure that
ensure safety
engineering resources
engine for
engine 37
end up
enables them
enabled python
enabled frameworks
empowering its
empower them
employing mutation
emphasize that
else however
else being
elements in
either usability
either on
either at
either already
eigen 13
efficiently from
efficiently executed
efficient interoperability
efficient gradient
efficient core
efficient and
efficiency of
effects of
effects and
effectiveness this
effectively ensures
effect of
effect disappears
ecosystem such
ecosystem of
ecosystem most
ecosystem it
eblearn 21
easy to
easy and
easily spawn
easily leverage
easily implemented
easily extended
easily adapts
easier to
ease of
eagerly all
eager semantics
eager mode
eager execution
each tensor
each month
each model
e5 2698
dynet which
dynet pytorch
dynet lush
dynamically allocate
dynamic tensor
dynamic programming
dynamic memory
dynamic eager
during training
during one
due to
drove the
dropout and
drop in
dramatically by
down this
down the
done on
domain specific
does so
does not
do that
do so
do not
dlpack 29
distributed computing
distributed computation
distinct pool
discriminator real_sample
discriminator parameters
discriminator fake
discriminator create_discriminator
discriminator and
disappears in
digits 27
differs significantly
differently by
differentiation which
differentiation using
differentiation system
differentiation integrated
differentiation cumbersome
differentiation but
differentiation and
differentiation 15
differentiating functions
differentiate through
differentiable via
differentiable functions
different machine
different approach
device utilization
device operators
development of
developing and
developed for
details all
detail the
detach fake_label
despite being
desired performance
designed to
designed specifically
design was
design their
design that
design seems
design process
design principles
design is
design greatly
design goals
design employed
design decisions
design choices
design assumption
design and
design also
describing pytorch
describe how
derivatives this
derivatives of
derivative or
depicts the
depends on
depend on
demonstrate the
deliver that
deliver great
deliver compelling
defining layers
defined behavior
define new
define by
deferring the
default implementation
def step
def forward
def __init__
deep learning
decisions and
debugging easy
debugging and
debuggers and
deallocation it
dealing with
daunting labor
datasets can
datasets behave
dataset preprocessing
dataloader class
dataflow on
dataflow graph
data with
data which
data we
data this
data structure
data stored
data scientists
data running
data processing
data parallelism
data of
data loading
data loaders
data flow
data files
data dataset
custom layer
custom differentiable
custom caching
custom allocator
current implementation
cumbersome instead
cudnn and
cudnn 22
cudamalloc and
cudafree slow
cudafree routine
cuda tensors
cuda stream
cuda runtime
cuda memory
cuda kernels
cuda kernel
cuda apis
cublas libraries
crucial for
cross thread
critical to
critical systems
created by
create first
create bindings
create and
cpython swift
cpus and
cpu with
cpu which
cpu to
cpu thread
cpu the
cpu scheduling
cpu runs
cpu or
cpu operators
cpu immediately
cpu however
cpu gpu
cpu before
cpu and
course part
counting scheme
counting mechanism
counting how
counting cpython
counted tools
count reaches
could utilize
could quickly
could leverage
costs of
cost of
corresponding execution
correspond to
corner cases
core pytorch
core libtorch
copying objects
copy on
copies have
copies and
cooperatively share
convolution matrix
convolution batch
converted arrays
convert between
converged on
conv2d 128
conv nn
controlled in
control the
control program
control of
control flow
control and
continuing to
continue to
containing number
consumes objects
constructors create
construction of
construct static
constant time
consistent with
consistent ideally
considerations in
consequently the
conforming to
conference on
conclusion and
concepts developed
computing utilities
computing power
computing libraries
computing have
computing derivatives
computes the
computed function
compute gradients
computations with
computations to
computations can
computation to
computation that
computation of
computation by
computation and
comprehensive set
comprehensive but
composing functionality
composed of
compose individual
components of
component of
complicated cases
complexity pytorch
complexity of
complexity inherent
complexity in
complex and
completes to
completely up
completely interchangeable
complete neural
compilation before
competitive performance
compelling performance
compatible it
comparing it
compare the
comparable to
community with
community to
community received
community moved
community has
community by
communities that
communication primitives
communication channel
communication and
commonly used
commonly established
common visualization
common technique
common for
common deep
common benchmarks
common antipattern
commoditization of
comes at
combining focus
combine multiple
combination has
colored areas
collector built
collection is
code will
code on
code most
code in
code executed
code describing
code by
code as
cntk tensorflow
cntk mxnet
cntk keras
cntk 845
closely resembles
closely integrated
closed proprietary
classify gray
classes whose
classes that
class member
class linearlayer
class fullbasicmodel
class bindings
chose to
choices dynamic
child processes
cheap and
characteristics in
changing needs
changing most
challenging for
chainer or
chainer dynet
chainer cntk
chainer and
chainer 778
certain corner
centric design
caveat is
cases without
cases result
cases it
case is
case insensitive
carefully optimizing
carefully insert
careful performance
careful implementation
careful and
care of
care not
can theoretically
can then
can rely
can reallocate
can only
can get
can easily
can differentiate
can define
can be
calls to
caller until
caffe in
caffe cntk
caffe chainer
caching tensor
cache of
bytes to
by the
by subclassing
by run
by quantifying
by pytorch
by python
by providing
by our
by leveraging
by keeping
by its
by integrating
by gpus
by extending
by developing
by deferring
by deep
by counting
by comprehensive
by composing
by comparing
by combining
by chainer
by carefully
by blocking
but we
but this
but the
but slightly
but not
but let
but later
but do
but complete
built into
built in
builds up
builds on
building blocks
building block
brand new
branches loops
bottom row
both sides
both references
both pytorch
both cases
body of
blocks of
blocking the
block its
block for
bindings to
bindings and
bidirectional exchange
between numpy
between its
better to
better interoperability
better 26
benign and
benefits of
benefit of
beneficial for
benchmarks the
benchmarks and
being equal
being closely
behind our
behind intuitive
behaviors at
behavior of
behavior for
behave like
before they
been an
become unneeded
become popular
become increasingly
because the
because taking
because it
because exact
be very
be useful
be used
be understood
be run
be represented
be pythonic
be performed
be observed
be leveraged
be handled
be further
be first
be extensible
be executed
be easily
be created
be completely
be arbitrary
be added
be achieved
be able
batching parallelization
batches of
batch normalization
basic parallel
basic inter
basic building
based programming
based optimization
based on
based deep
based around
based approach
balances speed
bad interactions
backward methods
away from
aware of
avoid this
avoid introducing
avoid fragmentation
avoid bad
average arithmetic
available to
available throughout
available during
availability and
autonomously playing
automatically the
automatically moves
automatically because
automatic differentiation
autograd function
autograd 16
authoring by
attribute this
at the
at any
asynchronously on
asynchronously execute
asynchronous dataflow
assumption simplifies
aspects of
aspect of
as well
as the
as tensors
as stateful
as shown
as scarce
as pythonic
as python
as proxy
as possible
as performance
as part
as numpy
as model
as matlab
as lua
as long
as gpus
as expected
as cudnn
as classes
as chainer
as caffe
as building
as apl
as an
as 2d
as 23
arxiv prints
arxiv papers
arrows pair
arrays often
arrays hence
arrays are
arrays and
array level
array based
around three
arithmetic complexity
areas are
are working
are usually
are used
are unacceptable
are typically
are summarized
are reflected
are python
are of
are not
are mentioned
are just
are in
are generated
are free
are four
are familiar
are exceptions
are designed
are correct
are benign
are available
are all
are actually
architecture we
architecture can
arbitrary python
arbitrary programs
approaches while
approaches are
approach which
approach to
approach the
approach provides
approach it
approach is
approach but
applies to
applied repeatedly
apl matlab
apis would
apis the
apis free
any particular
any number
any new
any given
any data
any component
antipattern among
another unique
another interesting
another additional
annotated traces
and whose
and which
and whether
and unexpected
and uncommon
and two
and towards
and those
and they
and then
and their
and theano
and the
and tensorflow
and take
and synchronization
and supporting
and some
and softmax
and similar
and scalability
and run
and result
and releasing
and recursive
and record
and reassigns
and pytorch
and pythonic
and provides
and productive
and production
and pragmatic
and parallelizing
and pandas
and others
and optimizers
and optimized
and one
and numpy
and moves
and more
and modeling
and mobilenet
and many
and management
and makes
and made
and lush
and lua
and keep
and julia
and its
and is
and initialize
and increasing
and in
and improves
and implementing
and implement
and how
and hidden
and hard
and future
and frees
and flux
and flexibility
and find
and external
and extensibility
and ensure
and efficient
and ease
and does
and distributed
and differentiable
and design
and data
and cudafree
and cublas
and cpu
and consistent
and common
and commoditization
and can
and basic
and backward
and automatically
and applies
and all
and advances
and __len__
and 24
analysis plotting
analysis needs
an overall
an output
an optimization
an iterator
an interpreted
an interesting
an input
an imperative
an explosion
an example
an essential
an entire
an efficient
an array
an allocation
amount of
amortized performance
among these
among them
among the
among arxiv
always use
although not
also provides
also intend
also integrates
also execute
also crucial
also available
also allowed
already utilize
along with
almost perfect
almost never
almost every
allows users
allows us
allows the
allows pytorch
allows for
allows changing
allowing them
allowing for
allowed us
allowed our
allow users
allow researchers
allow pytorch
allow for
allow concurrent
allocators pytorch
allocator which
allocator was
allocator starts
allocator can
allocator because
allocations without
allocations to
allocations end
allocation was
allocation is
allocated regions
allocated on
allocate an
alleviate this
all work
all the
all reduce
all previously
all of
all mentions
all memory
all gpus
all gpu
all expressed
all else
all designed
all aspects
algorithms efficiently
alexnet vgg
ai therefore
ahead of
again that
adversarial networks
advent of
advantage of
advances in
address new
additionally providing
additional synchronization
additional optimization
additional features
addition to
added by
add support
adapts to
adapt to
adam generator
adam discriminator
actually extremely
activations t2
activations self
activation similarly
across range
achieves competitive
achieve high
achieve compelling
achieve almost
account for
accepts added
acceptable 100
accelerators such
acceleration and
accelerated by
academic work
able to
ability of
__len__ the
__init__ super
__init__ self
__getitem__ the